{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Soil Classification \n# Part 1: Multiclass Classification\n\n**This project develops a multiclass classification model to distinguish Alluvial, Red, Black, and Clay soil images using deep learning, submitted for the Soil Classification Part 1 challenge.**\n","metadata":{}},{"cell_type":"markdown","source":"# Team Members\n\n- **Team Name**: Expendables\n- **Team Leader**: Sushmetha S R\n\n| Name                 | Role/Title                                                               | Affiliation                          | Email                     | GitHub Handle         |\n|----------------------|---------------------------------------------------------------------------|--------------------------------------|---------------------------|-----------------------|\n| Abhinav Chaitanya R  | BTech in Electronics and Communication Engineering, 2025                | Vellore Institute of Technology, VIT Chennai | abhinavchaitanya6@gmail.com | Abhinav302004         |\n| Arjun M              | BTech in Computer Science and Engineering, 2025                          | Vellore Institute of Technology, VIT Chennai | arjunm.0510@gmail.com     | ArjunM05              |\n| Harshavardhan S      | BTech in Computer Science and Engineering, 2025                          | Vellore Institute of Technology, VIT Chennai | harsak7@gmail.com         | harsha152003          |\n| Kiranchandran H      | BTech in Computer Science and Engineering (Cyber Physical Systems), 2025 | Vellore Institute of Technology, VIT Chennai | kiranchandranh@gmail.com  | kiranchh08            |\n| Sushmetha S R        | BTech in Computer Science and Engineering (AI & ML Specialization), 2025 | Vellore Institute of Technology, VIT Chennai | sush7niaa@gmail.com       | sushniaa              |","metadata":{}},{"cell_type":"markdown","source":"# Objective\n\nThe objective of this project is to develop a robust deep learning model for soil type classification using labeled soil images. The goal is to accurately predict the soil type from images by leveraging transfer learning with the EfficientNetV2 architecture, and to address data imbalance through the use of class-weighted focal loss.","metadata":{}},{"cell_type":"markdown","source":"# Dataset\n\n**Source:** The dataset is provided as part of the Soil Classification 2025 Challenge on Kaggle (`/kaggle/input/soil-classification/soil_classification-2025/`).\n* **Training Set:**\n  * Images stored in: `train/`\n  * Labels provided in: `train_labels.csv`\n* **Test Set:**\n  * Images stored in: `test/`\n  * Image IDs listed in: `test_ids.csv`\n  * Unseen images in: `test-soil-image/`\n\n\n**Dataset Statistics:**\n\n\n* Total training samples: 1222\n* Total test samples: 341\n* Number of unique classes: 4 (Alluvial, Red, Clay, Black)\n* Missing data: No missing values in image IDs or labels based on .isnull().sum() checks\n* Invalid or corrupt images: None detected based on sample inspection and successful loading\n\n\n**Preprocessing Steps:**\n\n* All images resized to 224Ã—224 to match the input size expected by EfficientNet-V2-S.\n\n* Images converted to RGB format to ensure consistency.\n\n* Applied ImageNet normalization: mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]\n\n* Label encoding applied to convert string class labels to numerical targets for training.\n\n**Label Description:**\n\n* Labels represent soil types.\n\n* Encoded using LabelEncoder to map string labels to integer classes: {'Alluvial soil': 0, 'Black Soil': 1, 'Clay soil': 2, 'Red soil': 3}","metadata":{}},{"cell_type":"markdown","source":"# Model\n\n**Architecture Used:**\n\n* Utilized EfficientNetV2-S, pretrained on ImageNet (torchvision.models.efficientnet_v2_s).\n\n* Replaced the final classifier head with a custom nn.Sequential block.\n\n  \n* The model outputs class probabilities for each soil type using softmax activation.\n\n**Loss Function:**\n\n* Employed Focal Loss to handle class imbalance.\n\n* Gamma = 2.0 to focus learning on harder examples.\n\n* Alpha = per-class weight vector based on inverse class frequency.\n\nThis helped prevent the model from being biased toward majority classes.\n\n**Optimization Details:**\n\n* Optimizer: Adam with a learning rate of 1e-4.\n  \n* Scheduler: StepLR with a step size of 7 and decay factor (gamma=0.1).\n\n  \n* Batch size: 32, with stratified train/validation split (80/20).\n\nTrained for 30 epochs, saving the best model based on F1-score on the validation set.","metadata":{}},{"cell_type":"markdown","source":"# Evaluation\n\n**Metrics**:\n  - F1-score (primary metric for the competition).\n  - Evaluated on the validation set.\n\n**Best Scores**:\n\n* F1_alluvial_soil: `[Value depends on run, e.g., 0.9500]`\n* F1_black_soil: `[e.g., 0.9500]`\n* F1_clay_soil: `[e.g., 0.9500]`\n* F1_red_soil: `[e.g., 0.9500]`\n* (Exact values are in `ml-metrics.json` generated by `Training.ipynb`).\n\n**Visuals**:\n\n* **Image Distribution:** Histogram of predicted class distribution on validation set to inspect prediction bias.\n* **Training History**: Line plots showing training loss and validation F1-score across 30 epochs. Saved as: `training_history.png`\n* **Confusion Matrix**: Visualized class-wise prediction accuracy on the validation set using a confusion matrix. Saved as: `confusion_matrix.png`","metadata":{}},{"cell_type":"markdown","source":"\n# Inference\n\nTo use the model for predictions:\n1. Run `Inference.ipynb`, which includes all training steps and inference.\n2. The notebook:\n   - Loads the best saved EfficientNetV2-S model (best_model.pth).\n   - Applies the same preprocessing pipeline to test images (resize, normalize).\n   - Selects the class with highest probability as the predicted label.\n   - Outputs final predictions to Submission.csv in (image_id, soil_type) format.\n3. For unseen images (e.g., `soil_test_1.jpg`, `soil_test_2.jpg`):\n   - The notebook processes each image, computes its similarity, and predicts the label.","metadata":{}}]}