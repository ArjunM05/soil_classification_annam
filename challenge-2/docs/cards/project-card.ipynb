{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f235e18",
   "metadata": {},
   "source": [
    "# Soil Classification \n",
    "# Part 2: Binary Classification  - (Soil vs. Non-Soil)\n",
    "\n",
    "**This project develops a binary classification model to distinguish soil from non-soil images using deep learning and feature similarity, submitted for the Soil Classification Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5497947c",
   "metadata": {},
   "source": [
    "# Team Members\n",
    "\n",
    "- **Team Name**: Expendables\n",
    "- **Team Leader**: Sushmetha S R\n",
    "\n",
    "| Name                 | Role/Title                                                               | Affiliation                          | Email                     | GitHub Handle         |\n",
    "|----------------------|---------------------------------------------------------------------------|--------------------------------------|---------------------------|-----------------------|\n",
    "| Abhinav Chaitanya R  | BTech in Electronics and Communication Engineering, 2025                | Vellore Institute of Technology, VIT Chennai | abhinavchaitanya6@gmail.com | Abhinav302004         |\n",
    "| Arjun M              | BTech in Computer Science and Engineering, 2025                          | Vellore Institute of Technology, VIT Chennai | arjunm.0510@gmail.com     | ArjunM05              |\n",
    "| Harshavardhan S      | BTech in Computer Science and Engineering, 2025                          | Vellore Institute of Technology, VIT Chennai | harsak7@gmail.com         | harsha152003          |\n",
    "| Kiranchandran H      | BTech in Computer Science and Engineering (Cyber Physical Systems), 2025 | Vellore Institute of Technology, VIT Chennai | kiranchandranh@gmail.com  | kiranchh08            |\n",
    "| Sushmetha S R        | BTech in Computer Science and Engineering (AI & ML Specialization), 2025 | Vellore Institute of Technology, VIT Chennai | sush7niaa@gmail.com       | sushniaa              |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c8d74e",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "The objective is to build a binary classifier to distinguish soil images from non-soil images (e.g., rocks, water) for the Soil Classification Part 2 challenge. This task is important for agricultural applications, such as automated soil analysis, and for improving land management by accurately identifying soil presence in diverse environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08c69b2",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "- **Source**: The dataset is provided by the Soil Classification Part 2 challenge on Kaggle (`/kaggle/input/soil-classification-part-2/soil_competition-2025/`).\n",
    "  - Training set: Images labeled as soil (`train/` and `train_labels.csv`).\n",
    "  - Test set: Images with a mix of soil and non-soil (`test/` and `test_ids.csv`).\n",
    "  - Unseen images: Additional non-soil images (`rock.png`, `sea.jpeg`) for testing.\n",
    "- **Dataset Statistics**:\n",
    "  - Total training images: 1222 (all labeled as soil).\n",
    "  - Total test images: 967 (mix of soil and non-soil).\n",
    "  - Sample image dimensions:\n",
    "    - Training: Varies, e.g., 728x728, 1160x522 (based on a sample of 5 images).\n",
    "    - Test: Varies significantly, e.g., 319x158, 1500x1125, 100x100 (based on a sample of 5 images).\n",
    "  - Invalid images: No invalid images found in a sample of 5 images from both training and test sets.\n",
    "- **Preprocessing Steps**:\n",
    "  - Resized images to 224x224 to match EfficientNet-B0 input requirements.\n",
    "  - Converted images to RGB and normalized using ImageNet statistics (`mean=[0.485, 0.456, 0.406]`, `std=[0.229, 0.224, 0.225]`).\n",
    "  - Skipped invalid images during dataset loading to ensure robustness.\n",
    "- **Label Description**:\n",
    "  - Training labels: All images are soil (label=1).\n",
    "  - Test labels: Binary classification (1=soil, 0=non-soil), to be predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71633ca4",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "- **Architecture Used**:\n",
    "  - Used EfficientNet-B0 pretrained on ImageNet.\n",
    "  - Removed the final classifier layer to output 1280-D feature embeddings.\n",
    "  - Applied PCA to reduce features to 100 dimensions for similarity computation.\n",
    "- **Loss Function**:\n",
    "  - Not applicable, as we used a similarity-based approach (cosine similarity) instead of training with a loss function.\n",
    "- **Optimization Details**:\n",
    "  - Used a feature similarity approach instead of traditional training.\n",
    "  - Computed cosine similarity to the top-5 training prototypes (k=5).\n",
    "  - Set a threshold at the 10th percentile of validation similarities to classify images as soil (label=1) or non-soil (label=0).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420f97e",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "- **Metrics**:\n",
    "  - F1-score (primary metric for the competition), precision, recall, and accuracy.\n",
    "  - Evaluated on the validation set (all soil images, label=1).\n",
    "- **Best Scores**:\n",
    "  - Validation F1-Score: [Value depends on run, e.g., 0.9500]\n",
    "  - Validation Precision: [e.g., 0.9300]\n",
    "  - Validation Recall: [e.g., 0.9700]\n",
    "  - Validation Accuracy: [e.g., 0.9000]\n",
    "  - (Exact values are in `ml-metrics.json` generated by `training.ipynb` or `inference.ipynb`).\n",
    "- **Visuals**:\n",
    "  - **Similarity Distribution**: Histogram of validation similarities with the threshold (saved as `similarity_distribution_validation.png`).\n",
    "  - **Sample Images**: Visualized sample training images to show soil characteristics (saved as `sample_training_images.png`).\n",
    "  - **PCA Feature Distribution**: Scatter plot of the first two PCA components (saved as `pca_feature_distribution.png`).\n",
    "  - **RGB Distribution**: Histogram of average RGB values to analyze color distribution (saved as `rgb_distribution_training.png`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158a0843",
   "metadata": {},
   "source": [
    "\n",
    "# Inference\n",
    "\n",
    "To use the model for predictions:\n",
    "1. Run `inference.ipynb`, which includes all training steps and inference.\n",
    "2. The notebook:\n",
    "   - Extracts features from the test set using EfficientNet-B0.\n",
    "   - Applies PCA (fitted on training data) to reduce features to 100 dimensions.\n",
    "   - Computes cosine similarity to the top-5 training prototypes.\n",
    "   - Classifies images using the threshold (10th percentile of validation similarities).\n",
    "   - Outputs predictions in `submission.csv` (`image_id`, `label` format).\n",
    "3. For unseen images (e.g., `rocks.png`, `sea.jpeg`):\n",
    "   - The notebook processes each image, computes its similarity, and predicts the label."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
